name: WikiDocumentation

# Example usage:
#   jobs:
#     run-docs-pipeline:
#       uses: org/repo/.github/workflows/WikiDocumentation.yaml@main
#       with:
#         app_name: "wiki-upload-test "

on:
  workflow_call:
    inputs:
      app_name:
        description: "Application name to be used when syncing documentation."
        required: true
        type: string
      base_path:
        description: "Base folder path in the Wiki assets (e.g. 'Pedro/Aplica√ß√µes')."
        required: true
        type: string
    secrets:
      WIKI_API_TOKEN:
        description: "API token for Wiki.js GraphQL access"
        required: true

permissions:
  contents: read
  actions: write

env:
  WIKI_URL: "http://wiki.franquinho.info/graphql"
  #WIKI_URL: "http://cyberwiki.internal.ctt.pt/graphql"
  #WIKI_API_TOKEN: ${{ secrets.WIKI_API_TOKEN_WIKILAB2  }}
  WIKI_API_TOKEN: ${{ secrets.WIKI_API_TOKEN }}
  WIKI_LOCALE: "en"
  BASE_PATH: ${{ inputs.base_path }}
  REPO_NAME: ${{ inputs.app_name != '' && inputs.app_name || github.event.repository.name }}
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }} 

jobs:
  # --- Phase 1: Setup ---
  setup-env:
    name: "Setup Environment"
    runs-on: ubuntu-latest
    outputs:
      BASE_PATH_SAFE: ${{ steps.export.outputs.BASE_PATH_SAFE }}
      ASSET_PATH_SAFE: ${{ steps.export.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Compute BASE_PATH_SAFE
        id: export
        run: |
          set -euo pipefail
          raw_base="${BASE_PATH:-}"
          raw_app="${REPO_NAME:-}"

          base_safe=$(echo "$raw_base" | iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null)
          base_safe=$(echo "$base_safe" | sed 's/[^a-zA-Z0-9\/-]//g')
          base_safe=$(echo "$base_safe" | sed 's#//*#/#g')
          base_safe="${base_safe%/}"
          echo "BASE_PATH_SAFE=$base_safe"
          echo "BASE_PATH_SAFE=$base_safe" >> "$GITHUB_OUTPUT"

          sanitize_segment() {
            local segment="$1"
            segment=$(echo "$segment" | iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null)
            segment=$(echo "$segment" | tr '[:upper:]' '[:lower:]')
            segment=$(echo "$segment" | sed 's/[^a-z0-9._-]/-/g')
            segment=$(echo "$segment" | sed 's/-\{2,\}/-/g')
            segment=$(echo "$segment" | sed 's/^-//; s/-$//')
            echo "$segment"
          }

          asset_path="${raw_base}/${raw_app}"
          asset_safe=""
          oldIFS="$IFS"
          IFS='/'
          read -r -a segments <<< "$asset_path"
          IFS="$oldIFS"
          for segment in "${segments[@]}"; do
            [ -z "$segment" ] && continue
            clean_segment=$(sanitize_segment "$segment")
            [ -z "$clean_segment" ] && continue
            asset_safe="${asset_safe}/${clean_segment}"
          done
          asset_safe="${asset_safe#/}"
          asset_safe="${asset_safe%/}"
          echo "ASSET_PATH_SAFE=$asset_safe"
          echo "ASSET_PATH_SAFE=$asset_safe" >> "$GITHUB_OUTPUT"

  # --- Phase 2: Wiki Discovery ---
  check-pages-folders:
    name: "Check if Pages and Folders are created"
    runs-on: ubuntu-latest
    needs: [setup-env]
    outputs:
      has_repo_path: ${{ steps.check.outputs.has_repo_path }}
      has_documentation_folder: ${{ steps.check.outputs.has_documentation_folder }}
      has_readme_page: ${{ steps.check.outputs.has_readme_page }}
      has_changelog_page: ${{ steps.check.outputs.has_changelog_page }}
      repo_path: ${{ steps.check.outputs.repo_path }}
      missing_files: ${{ steps.check.outputs.missing_files }}
      docs_files: ${{ steps.check.outputs.docs_files }}
      missing_count: ${{ steps.check.outputs.missing_count }}
    
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Query Wiki.js and verify structure
        id: check
        run: |
          set -euo pipefail

          # Definir Paths
          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          DOC_PREFIX="$(echo "${REPO_PATH}/documentation/" | sed 's#//*#/#g')"
          README_PATH="$(echo "${REPO_PATH}/readme" | sed 's#//*#/#g')"
          CHANGELOG_PATH="$(echo "${REPO_PATH}/changelog" | sed 's#//*#/#g')"

          echo "üîç Verifica√ß√µes:"
          echo "  ‚Ä¢ REPO_PATH      = $REPO_PATH"
          echo "  ‚Ä¢ DOC_PREFIX     = $DOC_PREFIX"
          echo

          QUERY=$(cat <<'GRAPHQL'
          query ($locale: String!) {
            pages {
              list(locale: $locale) {
                id
                path
                title
              }
            }
          }
          GRAPHQL
          )

          JSON_PAYLOAD=$(jq -n --arg q "$QUERY" --arg loc "$WIKI_LOCALE" '{query: $q, variables: { locale: $loc }}')

          echo "Querying Wiki.js for all pages..."

          RESULT=$(curl -sS -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")
          
          echo "$RESULT" | jq .

          # Verrificar se Existem erros no resultado
          ERR_CNT=$(echo "$RESULT" | jq '.errors | length // 0')
          if [ "$ERR_CNT" -gt 0 ]; then
            echo "‚ùå Erros na consulta:"
            echo "$RESULT" | jq '.errors'
            exit 1
          fi

          # Flags para verificar se os paths existem
          HAS_REPO_PATH=$(echo "$RESULT" | jq --arg path "$REPO_PATH" '[.data.pages.list[] | select(.path | startswith($path))] | length > 0')
          HAS_DOCUMENTATION_FOLDER=$(echo "$RESULT" | jq --arg path "$DOC_PREFIX" '[.data.pages.list[] | select(.path | startswith($path))] | length > 0')
          HAS_README_PAGE=$(echo "$RESULT" | jq --arg path "$README_PATH" '[.data.pages.list[] | select(.path == $path)] | length > 0')
          HAS_CHANGELOG_PAGE=$(echo "$RESULT" | jq --arg path "$CHANGELOG_PATH" '[.data.pages.list[] | select(.path == $path)] | length > 0')


          # List all .md files in documentation folder
          DOC_FILES=$(find documentation -type f -name "*.md" | sed 's#^documentation/##')
          DOC_FILES=($DOC_FILES)  # Convert to array

          # Remove the Extension from the filenames
          for i in "${!DOC_FILES[@]}"; do
            DOC_FILES[$i]=$(basename "${DOC_FILES[$i]}" .md)
          done

          # Verificar se esses arquivos existem na Wiki
          MISSING_FILES=()
          for FILE in "${DOC_FILES[@]}"; do
            FILE_PATH="${DOC_PREFIX}${FILE}"
            # echo "  ‚Ä¢ Checking if $FILE_PATH exists in Wiki..."
            EXISTS=$(echo "$RESULT" | jq --arg path "$FILE_PATH" '[.data.pages.list[] | select(.path == $path)] | length > 0')
            if [ "$EXISTS" != "true" ]; then
              MISSING_FILES+=("$FILE_PATH")
            fi
          done

          if [ ${#MISSING_FILES[@]} -gt 0 ]; then
            echo "  ‚Ä¢ Missing documentation files in Wiki:"
            for FILE in "${MISSING_FILES[@]}"; do
              echo "    - $FILE"
            done
          fi
          echo "‚úÖ Verifica√ß√µes conclu√≠das."

          # Set outputs
          echo "has_repo_path=$HAS_REPO_PATH" >> $GITHUB_OUTPUT
          echo "has_documentation_folder=$HAS_DOCUMENTATION_FOLDER" >> $GITHUB_OUTPUT
          echo "has_readme_page=$HAS_README_PAGE" >> $GITHUB_OUTPUT
          echo "has_changelog_page=$HAS_CHANGELOG_PAGE" >> $GITHUB_OUTPUT
          echo "repo_path=$REPO_PATH" >> $GITHUB_OUTPUT
          echo "missing_files=${MISSING_FILES[*]}" >> $GITHUB_OUTPUT
          echo "missing_count=${#MISSING_FILES[@]}" >> "$GITHUB_OUTPUT"
          echo "docs_files=${DOC_FILES[*]}" >> $GITHUB_OUTPUT

          # Echo dos outputs para debug
          echo "‚úÖ Outputs set:"
          echo "  ‚Ä¢ has_repo_path = $HAS_REPO_PATH"
          echo "  ‚Ä¢ has_documentation_folder = $HAS_DOCUMENTATION_FOLDER"
          echo "  ‚Ä¢ has_readme_page = $HAS_README_PAGE"
          echo "  ‚Ä¢ has_changelog_page = $HAS_CHANGELOG_PAGE"
          echo "  ‚Ä¢ missing_files = ${MISSING_FILES[*]}"
          echo "  ‚Ä¢ docs_files = ${DOC_FILES[*]}"

  # --- Phase 3: Change Detection ---
  check-altered-files:
    name: "Check Changed Files"
    runs-on: ubuntu-latest
    needs: [setup-env]
    outputs:
      docs_changed: ${{ steps.check.outputs.docs_changed }}
      readme_changed: ${{ steps.check.outputs.readme_changed }}
      changelog_changed: ${{ steps.check.outputs.changelog_changed }}
      doc_files_changed: ${{ steps.check.outputs.doc_files_changed }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Get changed files
        id: changed-files
        run: |
            # If github.event.before is empty (e.g., first commit or manual run), fallback to comparing with the previous commit or list all files
            if [ -z "${{ github.event.before }}" ] || [ "${{ github.event.before }}" = "0000000000000000000000000000000000000000" ]; then
              # If this is the first commit or before is empty, list all tracked files (including added ones)
              git ls-files > changed_files.txt
            else
              git fetch origin ${{ github.event.before }}
              git diff --name-only ${{ github.event.before }} ${{ github.sha }} > changed_files.txt
            fi
            cat changed_files.txt
            changed_files=$(cat changed_files.txt | tr '\n' ' ')
            echo "Changed files: $changed_files"

      - name: Check if documentation files changed
        id: check
        run: |
          if grep -qE '^documentation/.*\.md$' changed_files.txt; then
            echo "Documentation files have changed."
            echo "docs_changed=true" >> "$GITHUB_OUTPUT"
            
            # Get the list of changed documentation files for debugging
            echo "Changed documentation files:"
            DOC_FILES_CHANGED=$(grep -E '^documentation/.*\.md$' changed_files.txt)
            echo "$DOC_FILES_CHANGED"
            DOC_FILES_CHANGED=($DOC_FILES_CHANGED)
            echo "DOC_FILES_CHANGED=${DOC_FILES_CHANGED[*]}" >> "$GITHUB_OUTPUT"
          else
            echo "No documentation files have changed."
            echo "docs_changed=false" >> "$GITHUB_OUTPUT"
          fi

          if grep -qE '^README\.md$' changed_files.txt; then
            echo "README.md has changed."
            echo "readme_changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "README.md has not changed."
            echo "readme_changed=false" >> "$GITHUB_OUTPUT"
          fi

          if grep -qE '^CHANGELOG\.md$' changed_files.txt; then
            echo "CHANGELOG.md has changed."
            echo "changelog_changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "CHANGELOG.md has not changed."
            echo "changelog_changed=false" >> "$GITHUB_OUTPUT"
          fi
  
  # --- Phase 4: Content Creation ---
  create-missing-files:
    name: "Create Missing Documentation Files"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders]
    if: needs.check-pages-folders.outputs.has_repo_path == 'false' && fromJSON(needs.check-pages-folders.outputs.missing_count) > 0
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Create Documentation Missing Files
        run: |
          set -euo pipefail

          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          DOC_PREFIX="$(echo "${REPO_PATH}/documentation/" | sed 's#//*#/#g')"

          # Read missing files from output
          missing_files=(${{ needs.check-pages-folders.outputs.missing_files }})
          echo "Missing files to create: ${missing_files[*]}"

          ASSET_PATH_SAFE="${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}"
          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "$ASSET_PATH_SAFE" ]; then
            ASSET_PREFIX="/documentation/"
          fi
          echo "üîó Asset prefix: $ASSET_PREFIX"

          for FILE in "${missing_files[@]}"; do
            echo "  ‚Ä¢ Will create: $FILE"
            src_md="documentation/$(basename "$FILE").md"

            # Corrigir paths de imagens antes de enviar para o GraphQL
            echo "üîß Corrigindo paths de imagens em $src_md"
            CONTENT=$(tr -d '\r' < "$src_md")
            CONTENT=$(
              printf '%s\n' "$CONTENT" | sed -E \
                -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
                -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
            )

            # Limpeza adicional dos links de markdown para outros .md internos (mant√©m s√≥ ./documentation)
            CONTENT=$(
              printf '%s\n' "$CONTENT" | sed -E \
                -e 's#\]\([[:space:]]*/documentation/#](./documentation/#g' \
                -e 's#\]\([[:space:]]*documentation/#](./documentation/#g' \
                -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md([?#][^)]*)\)#](./documentation/\1\2)#g' \
                -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md\)#](./documentation/\1)#g'
            )

            CONTENT_JSON=$(jq -n --arg c "$CONTENT" '$c')

            TITLE="$(basename "$FILE")"
            echo "    - Title: $TITLE"

            QUERY='mutation ($content: String!, $locale: String!, $path: String!, $title: String!) { pages { create(path: $path, title: $title, content: $content, editor: "markdown", isPrivate: false, isPublished: true, locale: $locale, tags: [], description: "") { responseResult { succeeded slug message } page { id title path updatedAt } } } }'

            JSON_PAYLOAD=$(jq -n \
              --arg q "$QUERY" \
              --arg content "$CONTENT" \
              --arg loc "$WIKI_LOCALE" \
              --arg path "$FILE" \
              --arg title "$TITLE" \
              '{query: $q, variables: { content: $content, locale: $loc, path: $path, title: $title }}')

            RESULT=$(curl -s -X POST "$WIKI_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "$JSON_PAYLOAD")
            
            echo "$RESULT" | jq .

            SUCCEEDED=$(echo "$RESULT" | jq -r '.data.pages.create.responseResult.succeeded // empty')
            
            if [ "$SUCCEEDED" = "true" ]; then
              echo "‚úÖ Created: $FILE"
              PAGE_ID=$(echo "$RESULT" | jq -r .data.pages.create.page.id)
              echo "Page ID: $PAGE_ID"

              TITLE_SAFE="${TITLE^^}"
              TITLE_SAFE="${TITLE_SAFE//[^A-Z0-9_]/_}"
              VAR_NAME="WIKI_${TITLE_SAFE}_ID"

              echo "Saving $VAR_NAME=$PAGE_ID to repository variables‚Ä¶"
              # gh variable set "$VAR_NAME" --body "$PAGE_ID"
            else
              echo "‚ö†Ô∏è Failed to create: $FILE"
              echo "$RESULT" | jq .errors
              exit 1
            fi

          done
  
  create-readme-page:
    name: "Create README Page if missing"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders]
    if: needs.check-pages-folders.outputs.has_repo_path == 'false' && needs.check-pages-folders.outputs.has_readme_page == 'false'
    env:
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4
      
      - name: Create README Page in Wiki.js
        run: |
          set -euo pipefail

          # ------------------------------------------------------------
          # 1Ô∏è‚É£ Construir o caminho REPO_PATH de forma segura
          # ------------------------------------------------------------
          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          README_PATH="$(echo "${REPO_PATH}/readme" | sed 's#//*#/#g')"

          echo "üìÇ BASE_PATH: ${BASE_PATH}"
          echo "üìÑ REPO_PATH: ${REPO_PATH}"
          echo "üìò README_PATH: ${README_PATH}"

          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_PREFIX="/documentation/"
          fi

          # ------------------------------------------------------------
          # 3Ô∏è‚É£ Ler o conte√∫do do README.md (sem CRLF)
          # ------------------------------------------------------------
          if [ ! -f README.md ]; then
            echo "‚ùå README.md n√£o encontrado no reposit√≥rio."
            exit 1
          fi
          CONTENT=$(tr -d '\r' < README.md)

          CONTENT=$(
            printf '%s\n' "$CONTENT" | sed -E \
              -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
              -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
          )

          # ------------------------------------------------------------
          # 4Ô∏è‚É£ Reescrever links relativos (para documenta√ß√£o local)
          # ------------------------------------------------------------
          CONTENT=$(
            printf '%s\n' "$CONTENT" | sed -E \
              -e 's#\]\([[:space:]]*/documentation/#](./documentation/#g' \
              -e 's#\]\([[:space:]]*documentation/#](./documentation/#g' \
              -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md([?#][^)]*)\)#](./documentation/\1\2)#g' \
              -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md\)#](./documentation/\1)#g'
          )

          # ------------------------------------------------------------
          # 5Ô∏è‚É£ Construir query GraphQL
          # ------------------------------------------------------------
          QUERY='mutation ($content: String!, $locale: String!, $path: String!) {
            pages {
              create(
                path: $path,
                title: "README",
                content: $content,
                editor: "markdown",
                isPrivate: false,
                isPublished: true,
                locale: $locale,
                tags: [],
                description: ""
              ) {
                responseResult { succeeded slug message }
                page { id title path updatedAt }
              }
            }
          }'

          JSON_PAYLOAD=$(jq -n \
            --arg q "$QUERY" \
            --arg content "$CONTENT" \
            --arg loc "$WIKI_LOCALE" \
            --arg path "$README_PATH" \
            '{ query: $q, variables: { content: $content, locale: $loc, path: $path } }')

          # ------------------------------------------------------------
          # 6Ô∏è‚É£ Enviar para Wiki.js
          # ------------------------------------------------------------
          echo "üöÄ Enviando para Wiki.js..."
          RESULT=$(curl -s -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          echo "$RESULT" | jq .

          SUCCEEDED=$(echo "$RESULT" | jq -r '.data.pages.create.responseResult.succeeded // empty')
          if [ "$SUCCEEDED" = "true" ]; then
            PAGE_ID=$(echo "$RESULT" | jq -r .data.pages.create.page.id)
            echo "‚úÖ P√°gina criada com sucesso!"
            echo "üÜî Page ID: $PAGE_ID"
          else
            echo "‚ö†Ô∏è Falha ao criar p√°gina README"
            echo "$RESULT" | jq -r '.data.pages.create.responseResult.message'
            exit 1
          fi

  
  create-changelog-page:
    name: "Create CHANGELOG Page if missing"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders]
    if: needs.check-pages-folders.outputs.has_repo_path == 'false' && needs.check-pages-folders.outputs.has_changelog_page == 'false'
    env:
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Create CHANGELOG Page in Wiki.js
        run: |
          set -euo pipefail

          # ------------------------------------------------------------
          # 1Ô∏è‚É£ Construir caminho REPO_PATH e CHANGELOG_PATH
          # ------------------------------------------------------------
          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          CHANGELOG_PATH="$(echo "${REPO_PATH}/changelog" | sed 's#//*#/#g')"
          echo "üìÑ CHANGELOG_PATH: ${CHANGELOG_PATH}"

          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_PREFIX="/documentation/"
          fi

          # ------------------------------------------------------------
          # 3Ô∏è‚É£ Ler o conte√∫do do ficheiro CHANGELOG.md
          # ------------------------------------------------------------
          if [ ! -f CHANGELOG.md ]; then
            echo "‚ùå Ficheiro CHANGELOG.md n√£o encontrado no reposit√≥rio."
            exit 1
          fi

          CONTENT=$(tr -d '\r' < CHANGELOG.md)
          CONTENT=$(
            printf '%s\n' "$CONTENT" | sed -E \
              -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
              -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
          )
          echo "‚úÖ Conte√∫do do CHANGELOG carregado."

          # ------------------------------------------------------------
          # 4Ô∏è‚É£ Construir query GraphQL
          # ------------------------------------------------------------
          QUERY='mutation ($content: String!, $locale: String!, $path: String!) {
            pages {
              create(
                path: $path,
                title: "CHANGELOG",
                content: $content,
                editor: "markdown",
                isPrivate: false,
                isPublished: true,
                locale: $locale,
                tags: [],
                description: "All notable changes to this project will be documented in this file."
              ) {
                responseResult { succeeded slug message }
                page { id title path updatedAt }
              }
            }
          }'

          JSON_PAYLOAD=$(jq -n \
            --arg q "$QUERY" \
            --arg content "$CONTENT" \
            --arg loc "$WIKI_LOCALE" \
            --arg path "$CHANGELOG_PATH" \
            '{ query: $q, variables: { content: $content, locale: $loc, path: $path } }')

          # ------------------------------------------------------------
          # 5Ô∏è‚É£ Enviar para Wiki.js
          # ------------------------------------------------------------
          echo "üöÄ Criando p√°gina CHANGELOG..."
          RESULT=$(curl -s -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          echo "$RESULT" | jq .

          SUCCEEDED=$(echo "$RESULT" | jq -r '.data.pages.create.responseResult.succeeded // empty')
          if [ "$SUCCEEDED" = "true" ]; then
            PAGE_ID=$(echo "$RESULT" | jq -r .data.pages.create.page.id)
            echo "‚úÖ P√°gina CHANGELOG criada com sucesso!"
            echo "üÜî Page ID: $PAGE_ID"
          else
            echo "‚ö†Ô∏è Falha ao criar p√°gina CHANGELOG"
            echo "$RESULT" | jq -r '.data.pages.create.responseResult.message'
            exit 1
          fi


  # --- Phase 5: Content Updates ---
  update-docs-content:
    name: "Update Documentation Files in Wiki"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders, check-altered-files]
    if: needs.check-pages-folders.outputs.has_repo_path == 'true' && needs.check-altered-files.outputs.docs_changed == 'true'
    env:
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Query Wiki.js for existing pages
        id: query
        if: needs.check-altered-files.outputs.docs_changed == 'true'
        run: |
          set -euo pipefail
          echo "üîç Querying Wiki.js for existing pages..."

          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"

          QUERY='query ($locale: String!) { pages { list(locale: $locale) { id title path } } }'
          JSON_PAYLOAD=$(jq -n --arg q "$QUERY" --arg loc "$WIKI_LOCALE" '{query: $q, variables: { locale: $loc }}')

          RESULT=$(curl -sS -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          echo "$RESULT" | jq '.data.pages.list[] | select(.path | startswith("'"$REPO_PATH"'")) | {id, title, path}'

          # Exportar IDs como vari√°veis de ambiente
          echo "$RESULT" | jq -r --arg path "$REPO_PATH" \
            '.data.pages.list[]
             | select(.path | startswith($path))
             | "WIKI_PAGE_\(.title | ascii_upcase)="+(.id|tostring)' >> $GITHUB_ENV

          echo "‚úÖ Exported page IDs to environment."

      - name: Update the Files in Wiki
        if: needs.check-altered-files.outputs.doc_files_changed != ''
        run: |
          set -euo pipefail

          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          DOC_ROOT="$(echo "${REPO_PATH}/documentation/" | sed 's#//*#/#g')"

          # List all documentation files from the output
          docs_files=(${{ needs.check-pages-folders.outputs.docs_files }})
          echo "üìò Documentation files found: ${docs_files[*]}"

          # Remove Missing files (they will be created elsewhere)
          missing_files=(${{ needs.check-pages-folders.outputs.missing_files }})
          for MISSING in "${missing_files[@]}"; do
            MISSING_BASENAME="$(basename "$MISSING")"
            docs_files=("${docs_files[@]/$MISSING_BASENAME}")
          done
          echo "üìÑ After removing missing files: ${docs_files[*]}"

          # Keep only changed documentation files
          changed_files=(${{ needs.check-altered-files.outputs.doc_files_changed }})
          for i in "${!changed_files[@]}"; do
            changed_files[$i]=$(basename "${changed_files[$i]}" .md)
          done
          for i in "${!docs_files[@]}"; do
            if [[ ! " ${changed_files[*]} " =~ " ${docs_files[$i]} " ]]; then
              unset 'docs_files[i]'
            fi
          done

          if [ ${#docs_files[@]} -eq 0 ]; then
            echo "‚ÑπÔ∏è No documentation files to update. Exiting."
            exit 0
          fi

          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_PREFIX="/documentation/"
          fi

          for FILE in "${docs_files[@]}"; do
            echo "üìù Updating: $FILE"
            src_md="documentation/${FILE}.md"
            CONTENT=$(<"$src_md")

            CONTENT=$(printf '%s\n' "$CONTENT" | sed -E \
              -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
              -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
            )

            # Rewrite internal links
            CONTENT=$(printf '%s\n' "$CONTENT" | sed -E \
              -e 's#\]\([[:space:]]*/documentation/#](./documentation/#g' \
              -e 's#\]\([[:space:]]*documentation/#](./documentation/#g' \
              -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md([?#][^)]*)\)#](./documentation/\1\2)#g' \
              -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md\)#](./documentation/\1)#g'
            )

            # Determine the page ID dynamically from environment
            TITLE_SAFE="${FILE^^}"
            TITLE_SAFE="${TITLE_SAFE//[^A-Z0-9_]/_}"
            PAGE_ID_VAR="WIKI_PAGE_${TITLE_SAFE}"
            PAGE_ID="${!PAGE_ID_VAR:-}"

            if [ -z "$PAGE_ID" ]; then
              echo "‚ö†Ô∏è No existing Wiki page for '$FILE' found (skipping)."
              continue
            fi

            echo "üîó Found Wiki Page ID: $PAGE_ID"

            # Build GraphQL mutation
            QUERY='mutation ($id: Int!, $content: String!, $locale: String!) {
              pages {
                update(id: $id, content: $content, editor: "markdown",
                       isPrivate: false, isPublished: true, locale: $locale, tags: []) {
                  responseResult { succeeded message }
                  page { id title path updatedAt }
                }
              }
            }'

            JSON_PAYLOAD=$(jq -n \
              --arg q "$QUERY" \
              --argjson id "$PAGE_ID" \
              --arg content "$CONTENT" \
              --arg loc "$WIKI_LOCALE" \
              '{query: $q, variables: { id: $id, content: $content, locale: $loc }}')

            RESULT=$(curl -s -X POST "$WIKI_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "$JSON_PAYLOAD")

            SUCCEEDED=$(echo "$RESULT" | jq -r '.data.pages.update.responseResult.succeeded // empty')
            if [ "$SUCCEEDED" = "true" ]; then
              echo "‚úÖ Successfully updated: $FILE"
            else
              echo "‚ö†Ô∏è Failed to update: $FILE"
              echo "$RESULT" | jq .errors
              exit 1
            fi
          done


  update-readme-content:
    name: "Update ReadMe in Wiki"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders, check-altered-files]
    if: needs.check-pages-folders.outputs.has_repo_path == 'true' && needs.check-altered-files.outputs.readme_changed == 'true'
    env:
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Find README page ID in Wiki.js
        id: find_readme
        if: needs.check-altered-files.outputs.readme_changed == 'true'
        run: |
          set -euo pipefail
          echo "üîç Searching README page in Wiki.js..."

          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          README_PATH="$(echo "${REPO_PATH}/readme" | sed 's#//*#/#g')"

          QUERY='query ($locale: String!) { pages { list(locale: $locale) { id path title } } }'
          JSON_PAYLOAD=$(jq -n --arg q "$QUERY" --arg loc "$WIKI_LOCALE" '{query: $q, variables: { locale: $loc }}')

          RESULT=$(curl -sS -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          PAGE_ID=$(echo "$RESULT" | jq -r --arg path "$README_PATH" \
                     '.data.pages.list[] | select(.path == $path) | .id')

          if [ -z "$PAGE_ID" ] || [ "$PAGE_ID" = "null" ]; then
            echo "‚ö†Ô∏è README page not found in Wiki. Skipping update."
            echo "found=false" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Found README page ID: $PAGE_ID"
            echo "found=true" >> $GITHUB_OUTPUT
            echo "page_id=$PAGE_ID" >> $GITHUB_OUTPUT
          fi

      - name: Update README content in Wiki.js
        if: needs.check-altered-files.outputs.readme_changed == 'true' && steps.find_readme.outputs.found == 'true'
        run: |
          set -euo pipefail
          PAGE_ID="${{ steps.find_readme.outputs.page_id }}"

          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_PREFIX="/documentation/"
          fi

          CONTENT=$(tr -d '\r' < README.md)
          CONTENT=$(printf '%s\n' "$CONTENT" | sed -E \
            -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
            -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
          )
          CONTENT=$(printf '%s\n' "$CONTENT" | sed -E \
            -e 's#\]\([[:space:]]*/documentation/#](./documentation/#g' \
            -e 's#\]\([[:space:]]*documentation/#](./documentation/#g' \
            -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md([?#][^)]*)\)#](./documentation/\1\2)#g' \
            -e 's#\]\([[:space:]]*\./documentation/([^)]*)\.md\)#](./documentation/\1)#g')

          QUERY='mutation ($id: Int!, $content: String!, $locale: String!) {
            pages {
              update(id: $id, content: $content, editor: "markdown",
                     isPrivate: false, isPublished: true, locale: $locale,
                     tags: [], description: "") {
                responseResult { succeeded message }
              }
            }
          }'

          JSON_PAYLOAD=$(jq -n \
            --arg q "$QUERY" \
            --argjson id "$PAGE_ID" \
            --arg content "$CONTENT" \
            --arg loc "$WIKI_LOCALE" \
            '{query: $q, variables: { id: $id, content: $content, locale: $loc }}')

          RESULT=$(curl -s -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          SUCCESS=$(echo "$RESULT" | jq -r '.data.pages.update.responseResult.succeeded')
          if [ "$SUCCESS" = "true" ]; then
            echo "‚úÖ README updated successfully."
          else
            echo "‚ö†Ô∏è README update failed."
            echo "$RESULT" | jq .
            exit 1
          fi

  update-changelog-content:
    name: "Update Changelog in Wiki"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders, check-altered-files]
    if: needs.check-pages-folders.outputs.has_repo_path == 'true' && needs.check-altered-files.outputs.changelog_changed == 'true'
    env:
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Find CHANGELOG page ID in Wiki.js
        id: find_changelog
        if: needs.check-altered-files.outputs.changelog_changed == 'true'
        run: |
          set -euo pipefail
          echo "üîç Searching CHANGELOG page in Wiki.js..."

          REPO_PATH="$(echo "${BASE_PATH}/${REPO_NAME}" | sed 's#//*#/#g' | sed 's#/$##')"
          CHANGELOG_PATH="$(echo "${REPO_PATH}/changelog" | sed 's#//*#/#g')"

          QUERY='query ($locale: String!) { pages { list(locale: $locale) { id path title } } }'
          JSON_PAYLOAD=$(jq -n --arg q "$QUERY" --arg loc "$WIKI_LOCALE" '{query: $q, variables: { locale: $loc }}')

          RESULT=$(curl -sS -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          PAGE_ID=$(echo "$RESULT" | jq -r --arg path "$CHANGELOG_PATH" \
                     '.data.pages.list[] | select(.path == $path) | .id')

          if [ -z "$PAGE_ID" ] || [ "$PAGE_ID" = "null" ]; then
            echo "‚ö†Ô∏è CHANGELOG page not found in Wiki. Skipping update."
            echo "found=false" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Found CHANGELOG page ID: $PAGE_ID"
            echo "found=true" >> $GITHUB_OUTPUT
            echo "page_id=$PAGE_ID" >> $GITHUB_OUTPUT
          fi

      - name: Update CHANGELOG content in Wiki.js
        if: needs.check-altered-files.outputs.changelog_changed == 'true' && steps.find_changelog.outputs.found == 'true'
        run: |
          set -euo pipefail
          PAGE_ID="${{ steps.find_changelog.outputs.page_id }}"

          ASSET_PREFIX="/${ASSET_PATH_SAFE}/documentation/"
          if [ -z "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_PREFIX="/documentation/"
          fi

          CONTENT=$(tr -d '\r' < CHANGELOG.md)
          CONTENT=$(printf '%s\n' "$CONTENT" | sed -E \
            -e "s#\]\((<?)(\./)?documentation/#](\1${ASSET_PREFIX}#g" \
            -e "s#^(\[[^\]]+\]:[[:space:]]*)(<?)(\./)?documentation/#\1\2${ASSET_PREFIX}#g"
          )

          QUERY='mutation ($id: Int!, $content: String!, $locale: String!) {
            pages {
              update(id: $id, content: $content, editor: "markdown",
                     isPrivate: false, isPublished: true, locale: $locale,
                     tags: [], description: "") {
                responseResult { succeeded message }
              }
            }
          }'

          JSON_PAYLOAD=$(jq -n \
            --arg q "$QUERY" \
            --argjson id "$PAGE_ID" \
            --arg content "$CONTENT" \
            --arg loc "$WIKI_LOCALE" \
            '{query: $q, variables: { id: $id, content: $content, locale: $loc }}')

          RESULT=$(curl -s -X POST "$WIKI_URL" \
            -H "Authorization: Bearer $WIKI_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          SUCCESS=$(echo "$RESULT" | jq -r '.data.pages.update.responseResult.succeeded')
          if [ "$SUCCESS" = "true" ]; then
            echo "‚úÖ CHANGELOG updated successfully."
          else
            echo "‚ö†Ô∏è CHANGELOG update failed."
            echo "$RESULT" | jq .
            exit 1
          fi

  # --- Phase 6: Asset Upload ---
  upload-docs-media:
    name: "Upload Documentation Media"
    runs-on: ubuntu-latest
    needs: [setup-env, check-pages-folders]
    if: needs.check-pages-folders.outputs.has_repo_path == 'false'
    env:
      BASE_PATH_SAFE: ${{ needs.setup-env.outputs.BASE_PATH_SAFE }}
      ASSET_PATH_SAFE: ${{ needs.setup-env.outputs.ASSET_PATH_SAFE }}
      PARENT_FOLDER_ID: "1"
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Detect Media Files
        id: detect
        run: |
          MEDIA_FILES=$(find documentation/ -type f ! -name "*.md")
          echo "MEDIA_FILES<<EOF" >> "$GITHUB_ENV"
          echo "$MEDIA_FILES" >> "$GITHUB_ENV"
          echo "EOF" >> "$GITHUB_ENV"
          echo "Ficheiros encontrados:"
          echo "$MEDIA_FILES"

      - name: Get Repository Name
        id: repo
        run: |
          repo_name="${GITHUB_REPOSITORY##*/}"
          echo "REPO_NAME=${repo_name,,}" >> "$GITHUB_ENV"
          echo "Repository name: ${repo_name,,}"

      - name: Criar estrutura de pastas aninhadas no Wiki.js
        id: criar-pastas
        env:
          WIKI_API_TOKEN: ${{ secrets.WIKI_API_TOKEN }}
          APP_NAME: ${{ inputs.app_name || github.event.repository.name }}
        run: |
          set -euo pipefail

          # === CONFIGURA√á√ÉO ===
          APP_NAME="${APP_NAME,,}"  # lowercase
          if [ -n "${ASSET_PATH_SAFE:-}" ]; then
            ASSET_FOLDER_PATH="${ASSET_PATH_SAFE}/documentation"
          else
            ASSET_FOLDER_PATH="${BASE_PATH}/${APP_NAME}/documentation"
          fi

          BASE_URL="${WIKI_URL%/}"
          if [[ "$BASE_URL" =~ /graphql$ ]]; then
            GRAPHQL_URL="$BASE_URL"
            BASE_URL="${BASE_URL%/graphql}"
            BASE_URL="${BASE_URL%/}"
            UPLOAD_URL="${BASE_URL}/u"
          else
            GRAPHQL_URL="${BASE_URL}/graphql"
            UPLOAD_URL="${BASE_URL}/u"
          fi

          # Fun√ß√£o: slugificar (imitando comportamento Wiki.js)
          slugify() {
            echo "$1" \
              | tr '[:upper:]' '[:lower:]' \
              | sed -E 's/[[:space:]]+/-/g' \
              | sed -E 's/[^a-z0-9._-]+/-/g' \
              | sed -E 's/-{2,}/-/g' \
              | sed -E 's/^-+|-+$//g'
          }

          # Fun√ß√£o: obter ID da pasta
          get_folder_id() {
            local parent_id="$1"
            local name_raw="$2"
            [[ -z "$parent_id" ]] && parent_id=0

            local name_lc slug
            name_lc="$(echo "$name_raw" | tr '[:upper:]' '[:lower:]')"
            slug="$(slugify "$name_raw")"

            local QUERY JSON RESULT
            QUERY="query { assets { folders(parentFolderId: $parent_id) { id name slug } } }"
            JSON=$(jq -n --arg q "$QUERY" '{ query: $q }')
            RESULT=$(curl -s -X POST "$GRAPHQL_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "$JSON")

            echo "$RESULT" | jq -r --arg SLUG "$slug" --arg NAME_LC "$name_lc" '
              .data.assets.folders[]? 
              | select((.slug == $SLUG) or ((.name|ascii_downcase) == $NAME_LC)) 
              | .id
            '
          }

          # Fun√ß√£o: criar pasta
          create_folder() {
            local parent_id="$1"
            local name_raw="$2"
            [[ -z "$parent_id" ]] && parent_id=0
            local slug
            slug="$(slugify "$name_raw")"

            local MUTATION JSON RESULT
            MUTATION="mutation { assets { createFolder(parentFolderId: $parent_id, slug: \"$slug\", name: \"$name_raw\") { responseResult { succeeded message } } } }"
            JSON=$(jq -n --arg q "$MUTATION" '{ query: $q }')
            RESULT=$(curl -s -X POST "$GRAPHQL_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "$JSON")

            echo "$RESULT" | jq .
            local SUCCESS
            SUCCESS=$(echo "$RESULT" | jq -r '.data.assets.createFolder.responseResult.succeeded')
            if [ "$SUCCESS" != "true" ]; then
              echo "Erro a criar pasta '$name_raw'"
              exit 1
            fi
          }

          echo "Estrutura alvo: $ASSET_FOLDER_PATH"
          IFS='/' read -ra PARTS <<< "$ASSET_FOLDER_PATH"

          CURRENT_PARENT=""
          for PART in "${PARTS[@]}"; do
            echo "‚Üí Verificar/criar '$PART' sob parent '${CURRENT_PARENT:-0}'"
            FOLDER_ID="$(get_folder_id "$CURRENT_PARENT" "$PART" | head -n1 || true)"

            if [[ -z "$FOLDER_ID" || "$FOLDER_ID" == "null" ]]; then
              echo "‚Ä¶ n√£o existe, a criar '$PART'‚Ä¶"
              create_folder "$CURRENT_PARENT" "$PART"
              FOLDER_ID="$(get_folder_id "$CURRENT_PARENT" "$PART" | head -n1 || true)"
              if [[ -z "$FOLDER_ID" || "$FOLDER_ID" == "null" ]]; then
                echo "Falha a obter ID da pasta '$PART' ap√≥s cria√ß√£o."
                exit 1
              fi
              echo "‚úì criada: id=$FOLDER_ID"
            else
              echo "‚úì j√° existe: id=$FOLDER_ID"
            fi

            CURRENT_PARENT="$FOLDER_ID"
          done

          echo "FOLDER_ID final = $FOLDER_ID"
          echo "FOLDER_ID=$FOLDER_ID" >> "$GITHUB_ENV"
          echo "UPLOAD_URL=$UPLOAD_URL" >> "$GITHUB_ENV"
          echo "GRAPHQL_URL=$GRAPHQL_URL" >> "$GITHUB_ENV"

      - name: Upload Media Files
        env:
          WIKI_API_TOKEN: ${{ secrets.WIKI_API_TOKEN }}
          APP_NAME: ${{ inputs.app_name || github.event.repository.name }}
        run: |
          set -euo pipefail
          GRAPHQL_URL="${GRAPHQL_URL:-$WIKI_URL}"
          UPLOAD_URL="${UPLOAD_URL:-${WIKI_URL%/}/u}"
          if [[ "$UPLOAD_URL" =~ /graphql/u$ ]]; then
            TRIMMED="${UPLOAD_URL%/graphql/u}"
            TRIMMED="${TRIMMED%/}"
            UPLOAD_URL="${TRIMMED}/u"
          fi

          DOC_ROOT_FOLDER_ID="${DOC_ROOT_FOLDER_ID:-${FOLDER_ID:-}}"
          if [ -z "$DOC_ROOT_FOLDER_ID" ]; then
            echo "ERROR: DOC_ROOT_FOLDER_ID not defined. Previous step may have failed."
            exit 1
          fi

          if [ -z "${MEDIA_FILES:-}" ]; then
            echo "No media files to upload."
            exit 0
          fi

          call_graphql() {
            local payload="$1"
            curl -s -X POST "$GRAPHQL_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -H "Content-Type: application/json" \
              --data "$payload"
          }

          sanitize_slug() {
            local slug
            slug=$(echo "$1" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9_-]/-/g')
            slug=$(echo "$slug" | sed 's/-\{2,\}/-/g; s/^-//; s/-$//')
            if [ -z "$slug" ]; then
              slug="assets-folder"
            fi
            echo "$slug"
          }

          folders_query='query($parent: Int!) { assets { folders(parentFolderId: $parent) { id name slug } } }'
          create_folder_mutation='mutation($parent: Int!, $slug: String!, $name: String!) { assets { createFolder(parentFolderId: $parent, slug: $slug, name: $name) { responseResult { succeeded message }, folder { id name slug } } } }'

          declare -A FOLDER_CACHE=()

          ensure_child_folder() {
            local parent="$1"
            local name="$2"
            local slug="$3"
            local cache_key="${parent}:${slug}"
            if [[ -n "${FOLDER_CACHE[$cache_key]:-}" ]]; then
              echo "${FOLDER_CACHE[$cache_key]}"
              return 0
            fi

            local payload result folder_id
            payload=$(jq -n \
              --arg q "$folders_query" \
              --argjson parent "$parent" \
              '{ query: $q, variables: { parent: $parent } }')
            result=$(call_graphql "$payload")
            if ! echo "$result" | jq . >/dev/null 2>&1; then
              echo "ERROR: Non-JSON response when querying folders (parent $parent):"
              echo "$result"
              exit 1
            fi
            folder_id=$(echo "$result" | jq -r --arg name "$name" --arg slug "$slug" '
              (.data.assets.folders // [])[]
              | select(
                  (.name // "" | ascii_downcase) == ($name | ascii_downcase)
                  or (.slug // "" | ascii_downcase) == ($slug | ascii_downcase)
                )
              | .id' | head -n 1)
            if [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              FOLDER_CACHE["$cache_key"]="$folder_id"
              echo "$folder_id"
              return 0
            fi

            payload=$(jq -n \
              --arg q "$create_folder_mutation" \
              --argjson parent "$parent" \
              --arg slug "$slug" \
              --arg name "$name" \
              '{ query: $q, variables: { parent: $parent, slug: $slug, name: $name } }')
            result=$(call_graphql "$payload")
            if ! echo "$result" | jq . >/dev/null 2>&1; then
              echo "ERROR: Non-JSON response when creating folder '$name' (parent $parent):"
              echo "$result"
              exit 1
            fi
            local succeeded
            succeeded=$(echo "$result" | jq -r '.data.assets.createFolder.responseResult.succeeded // "false"')
            if [ "$succeeded" != "true" ]; then
              echo "ERROR: Wiki.js reported failure when creating folder '$name' (parent $parent):"
              echo "$result" | jq .
              exit 1
            fi
            folder_id=$(echo "$result" | jq -r '.data.assets.createFolder.folder.id // .data.assets.createFolder.id')
            if [ -z "$folder_id" ] || [ "$folder_id" = "null" ]; then
              echo "ERROR: Folder ID missing after creating '$name' (parent $parent)."
              echo "$result" | jq .
              exit 1
            fi
            FOLDER_CACHE["$cache_key"]="$folder_id"
            echo "$folder_id"
          }

          ensure_path() {
            local parent="$1"
            local path="$2"
            if [ -z "$path" ] || [ "$path" = "." ]; then
              echo "$parent"
              return 0
            fi

            local current="$parent"
            local oldIFS="$IFS"
            IFS='/'
            read -r -a segments <<< "$path"
            IFS="$oldIFS"
            for segment in "${segments[@]}"; do
              [ -z "$segment" ] && continue
              [ "$segment" = "." ] && continue
              if [ "$segment" = ".." ]; then
                echo "ERROR: Unsupported path segment '..' in '$path'."
                exit 1
              fi
              local slug
              slug=$(sanitize_slug "$segment")
              current=$(ensure_child_folder "$current" "$segment" "$slug")
            done
            echo "$current"
          }

          echo "$MEDIA_FILES" | while IFS= read -r filepath || [ -n "$filepath" ]; do
            [ -z "$filepath" ] && continue
            if [ ! -f "$filepath" ]; then
              echo "File '$filepath' not found locally, skipping."
              continue
            fi

            target_folder_id="$DOC_ROOT_FOLDER_ID"
            relative_path="$filepath"
            relative_dir=""
            if [[ "$filepath" == documentation/* ]]; then
              relative_path="${filepath#documentation/}"
              if [[ "$relative_path" == */* ]]; then
                relative_dir="${relative_path%/*}"
                target_folder_id=$(ensure_path "$DOC_ROOT_FOLDER_ID" "$relative_dir")
              fi
            fi

            echo "Uploading $filepath"
            RESPONSE_WITH_STATUS=$(curl -s -w "\n%{http_code}" -X POST "$UPLOAD_URL" \
              -H "Authorization: Bearer $WIKI_API_TOKEN" \
              -F "mediaUpload={\"folderId\":$target_folder_id}" \
              -F "mediaUpload=@$filepath")
            HTTP_STATUS=$(echo "$RESPONSE_WITH_STATUS" | tail -n1)
            BODY=$(echo "$RESPONSE_WITH_STATUS" | sed '$d')
            if [[ "$HTTP_STATUS" =~ ^2 ]]; then
              if echo "$BODY" | jq . >/dev/null 2>&1; then
                echo "$BODY" | jq .
              else
                echo "Upload succeeded (HTTP $HTTP_STATUS) for file: $filepath"
                echo "$BODY"
              fi
            else
              echo "Upload failed (HTTP $HTTP_STATUS) for file: $filepath"
              if echo "$BODY" | jq . >/dev/null 2>&1; then
                echo "$BODY" | jq .
              else
                echo "$BODY"
              fi
              exit 1
            fi
          done
